{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Women_Nlp1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlwTVXkK3dd3"
      },
      "source": [
        "#References are taken from Restaurant Review Project(https://www.geeksforgeeks.org/python-nlp-analysis-of-restaurant-reviews/)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Tzxkvv7O47ia",
        "outputId": "66f0c87a-af0d-425c-8372-21d4d13e33dd"
      },
      "source": [
        "df = pd.read_excel('Women_nlp.xlsx')\n",
        "df.head()#Orignial data set"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Recommended IND</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Review Text  Recommended IND\n",
              "0  Absolutely wonderful - silky and sexy and comf...                1\n",
              "1  Love this dress!  it's sooo pretty.  i happene...                1\n",
              "2  I had such high hopes for this dress and reall...                0\n",
              "3  I love, love, love this jumpsuit. it's fun, fl...                1\n",
              "4  This shirt is very flattering to all due to th...                1"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eYubfxk5r_5",
        "outputId": "174c50d9-5fc5-4b24-9396-e1eaa1b37a8c"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23488, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xReArq2B6Vs4",
        "outputId": "95929f43-f85e-4aef-d236-3c255f22d9c1"
      },
      "source": [
        "df.isna().sum()  #We are getting 845 Review Text with NAN cluln , we need to remove the same"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Review Text        845\n",
              "Recommended IND      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mzgQ9x97RZO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "da96ea70-4138-4469-bd2f-550c1d61e49b"
      },
      "source": [
        "\n",
        "#Drop row columns\n",
        "df1 = df.dropna() \n",
        "df1.head()\n",
        "\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_0</th>\n",
              "      <th>index</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Recommended IND</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   level_0  ...  Recommended IND\n",
              "0        0  ...                1\n",
              "1        1  ...                1\n",
              "2        2  ...                0\n",
              "3        3  ...                1\n",
              "4        4  ...                1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HROOxaLd7RcE",
        "outputId": "355e86e7-8488-46e4-ec7e-5d73c01c8bab"
      },
      "source": [
        "df1.isna().sum() #no nan value in Reviews"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "level_0            0\n",
              "index              0\n",
              "Review Text        0\n",
              "Recommended IND    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuxOCy9y6f18",
        "outputId": "78892e0e-36b8-4031-a633-f759e8f89db9"
      },
      "source": [
        "df1.info()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 22643 entries, 0 to 22642\n",
            "Data columns (total 4 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   level_0          22643 non-null  int64 \n",
            " 1   index            22643 non-null  int64 \n",
            " 2   Review Text      22643 non-null  object\n",
            " 3   Recommended IND  22643 non-null  int64 \n",
            "dtypes: int64(3), object(1)\n",
            "memory usage: 884.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kewPHTxz7Dot",
        "outputId": "2665fab1-b54b-4c43-e4c9-45457d864750"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22643, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhyG8Cl7-llv",
        "outputId": "2e6b85b5-5eec-47ca-c7f2-bd20173fa04e"
      },
      "source": [
        "# library to clean data\n",
        "import re\n",
        " \n",
        "# Natural Language Tool Kit\n",
        "import nltk\n",
        " \n",
        "nltk.download('stopwords')\n",
        " \n",
        "# to remove stopword\n",
        "from nltk.corpus import stopwords\n",
        " \n",
        "# for Stemming propose\n",
        "from nltk.stem.porter import PorterStemmer\n",
        " \n",
        "# Initialize empty array\n",
        "# to append clean text\n",
        "corpus = []\n",
        " \n",
        "# 22643 (reviews) rows to clean\n",
        "for i in range(0, 22643):\n",
        "     \n",
        "    # column : \"Review\", row ith\n",
        "    review = re.sub('[^a-zA-Z]', ' ', df1['Review Text'][i])\n",
        "     \n",
        "    # convert all cases to lower cases\n",
        "    review = review.lower()\n",
        "     \n",
        "    # split to array(default delimiter is \" \")\n",
        "    review = review.split()\n",
        "     \n",
        "    # creating PorterStemmer object to\n",
        "    # take main stem of each word\n",
        "    ps = PorterStemmer()\n",
        "     \n",
        "    # loop for stemming each word\n",
        "    # in string array at ith row   \n",
        "    review = [ps.stem(word) for word in review\n",
        "                if not word in set(stopwords.words('english'))]\n",
        "                 \n",
        "    # rejoin all string array elements\n",
        "    # to create back into a string\n",
        "    review = ' '.join(review)\n",
        "     \n",
        "    # append each string to create\n",
        "    # array of clean text\n",
        "    corpus.append(review)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqG0vFbyGgJq",
        "outputId": "ada88716-09c1-49cd-8e14-c1122fce0126"
      },
      "source": [
        "print(corpus)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYVjKLyK_6j7"
      },
      "source": [
        "#Creating Bag of Models\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer  \n",
        "#To extract max 1500 feature,\"max_features\" is attribute to experiment with to get better results\n",
        "cv = CountVectorizer(max_features=1500)  #Max feature is nothing but number of imp words are categorized by model on which our model is being trained.Our model categorized 9000 words while we check max feature on 9000 workds we are getting poor accurcay of 40%,while we checked model on 1000 feature we get 73% accuracy.If we further reduce the max feature to 100 words we getting accuracy of 76%\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "# y contains answers if review is positive or negative ,\"0\" for negative and \"1\" for Positive\n",
        "y = df1.iloc[:, -1].values"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8si3Iqk_TMt",
        "outputId": "35f0d25f-5e13-44e3-d03f-7cb52f962395"
      },
      "source": [
        "#finding words in X(review Column)\n",
        "\n",
        "len(X[0])  #We got 1500 words taken from all the reviews with the help of tokenization, We will take 9000 words for our bag of words model."
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1500"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKaZnlnsAb96"
      },
      "source": [
        "#Splitting model in train and test set\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jVhE8ODAzNp"
      },
      "source": [
        "#Train Naives bayes model on Training Set\n",
        "\n",
        "#from sklearn.naive_bayes import GaussianNB\n",
        "#classifier = GaussianNB()\n",
        "#classifier.fit(X_train, y_train)\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7DyjVUpBnhs",
        "outputId": "4195198b-e70d-44f9-b0b8-0cd386f32595"
      },
      "source": [
        "#Train set result,73 %accuracy on max feature of 1000,feel free to change max feature in naives bayes to check accuracy on another max feature\n",
        "\n",
        "\n",
        "#y_pred = classifier.predict(X_train)\n",
        "#print(np.concatenate((y_pred.reshape(len(y_pred),1), y_train.reshape(len(y_train),1)),1))\n",
        "\n",
        "#Confusion matrix for Train Set\n",
        "#from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "#cm = confusion_matrix(y_train, y_pred)\n",
        "#print(cm)\n",
        "#accuracy_score(y_train, y_pred)\n",
        "\n",
        "# Fitting Random Forest Classification\n",
        "# to the Training set\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        " \n",
        "# n_estimators can be said as number of\n",
        "# trees, experiment with n_estimators\n",
        "# to get better results\n",
        "model = RandomForestClassifier(n_estimators = 501,\n",
        "                            criterion = 'entropy')\n",
        "                             \n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=501,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b1QHnqiA72c",
        "outputId": "ffa6efcd-5263-4302-f856-573c99f27f7d"
      },
      "source": [
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        " \n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        " \n",
        "cm\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 372  464]\n",
            " [1573 2120]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5502318392581144"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzxKZB5w9IgA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLYsbcrO9Ii4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwK5-9FIB-lu"
      },
      "source": [
        "# Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1kiO9kACE6s"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QG7sxmoCIvN"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTfaCIzdCLPA"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCK6vQ5QCQJe"
      },
      "source": [
        "dataset = pd.read_excel('Women_nlp.xlsx')"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDbeTO339ftD",
        "outputId": "8a00f3c6-60fd-4bca-a4c6-fbb37ca49c30"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23488 entries, 0 to 23487\n",
            "Data columns (total 2 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   Review Text      22643 non-null  object\n",
            " 1   Recommended IND  23488 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 367.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSKNq48E9jJI",
        "outputId": "ba8f2c76-5284-4268-c1df-fde3e6af985b"
      },
      "source": [
        "dataset.isna().sum()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Review Text        845\n",
              "Recommended IND      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXAwY8ic9ras",
        "outputId": "aa00bffd-3a0c-4b4d-d11a-9448dae8feae"
      },
      "source": [
        "#Drop row columns\n",
        "dataset1 = df.dropna() \n",
        "dataset1.head()\n",
        "dataset1.info()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 22643 entries, 0 to 22642\n",
            "Data columns (total 4 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   level_0          22643 non-null  int64 \n",
            " 1   index            22643 non-null  int64 \n",
            " 2   Review Text      22643 non-null  object\n",
            " 3   Recommended IND  22643 non-null  int64 \n",
            "dtypes: int64(3), object(1)\n",
            "memory usage: 884.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qekztq71CixT"
      },
      "source": [
        "## Cleaning the texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u_yXh9dCmEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb0ef59-63c4-404e-a653-7701999b801e"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "corpus = []\n",
        "for i in range(0,22643 ):\n",
        "  review = re.sub('[^a-zA-Z]', ' ', dataset1['Review Text'][i])\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  ps = PorterStemmer()\n",
        "  all_stopwords = stopwords.words('english')\n",
        "  all_stopwords.remove('not')\n",
        "  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpGWdrzGoAsL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ba55a88-659c-4092-8f0c-7bcd70eb53e7"
      },
      "source": [
        "print(corpus)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLqmAkANCp1-"
      },
      "source": [
        "## Creating the Bag of Words model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qroF7XcSCvY3"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features = 100)# We select only 100 words as max features and Accuracy increased to 75% \n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "y = dataset1.iloc[:, -1].values"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH_VjgPzC2cd"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQXYM5VzDDDI"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkIq23vEDIPt"
      },
      "source": [
        "## Training the Naive Bayes model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS9oiDXXDRdI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e0e1089-c0d5-43b0-a322-073e09d73825"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JaRM7zXDWUy"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iif0CVhFDaMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ab4f78-31a3-41da-80f2-44fbc926f54c"
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " ...\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoMltea5Dir1"
      },
      "source": [
        "## Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj9IU6MxDnvo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "496156cc-b4c0-401e-e55d-680aa4cee49b"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 649  208]\n",
            " [ 884 2788]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.758887171561051"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btPZmUbn-2op"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}