{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled32.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlwTVXkK3dd3"
      },
      "source": [
        "#References are taken from Restaurant Review Project(https://www.geeksforgeeks.org/python-nlp-analysis-of-restaurant-reviews/)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "Tzxkvv7O47ia",
        "outputId": "5d9603ed-b257-42a6-95bc-7cf53a7196f7"
      },
      "source": [
        "df = pd.read_excel('Women_nlp.xlsx')\n",
        "df.head()#Orignial data set"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Recommended IND</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Review Text  Recommended IND\n",
              "0  Absolutely wonderful - silky and sexy and comf...                1\n",
              "1  Love this dress!  it's sooo pretty.  i happene...                1\n",
              "2  I had such high hopes for this dress and reall...                0\n",
              "3  I love, love, love this jumpsuit. it's fun, fl...                1\n",
              "4  This shirt is very flattering to all due to th...                1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eYubfxk5r_5",
        "outputId": "6ca87229-4aa5-4e5e-e0d1-d00779b99e22"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23488, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xReArq2B6Vs4",
        "outputId": "18087e1c-8263-42be-d5cd-6225c09057d9"
      },
      "source": [
        "df.isna().sum()  #We are getting 845 Review Text with NAN cluln , we need to remove the same"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Review Text        845\n",
              "Recommended IND      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mzgQ9x97RZO"
      },
      "source": [
        "df=df.dropna()\n",
        "# reset's row indexes in case any rows were dropped\n"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HROOxaLd7RcE",
        "outputId": "5ce6151d-afc0-41a3-cf60-7cc6348aed20"
      },
      "source": [
        "df.isna().sum() #no nan value in Reviews"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Review Text        0\n",
              "Recommended IND    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuxOCy9y6f18",
        "outputId": "be92e349-3cd5-4e98-922c-8c6f4ddd59df"
      },
      "source": [
        "df1.info()"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 22643 entries, 0 to 22642\n",
            "Data columns (total 3 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   index            22643 non-null  int64 \n",
            " 1   Review Text      22643 non-null  object\n",
            " 2   Recommended IND  22643 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 1.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kewPHTxz7Dot",
        "outputId": "2a485ad0-07d7-422a-b281-0340db9ee6a5"
      },
      "source": [
        "df1.shape  #845 nan review coulmns are removed"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22643, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhyG8Cl7-llv",
        "outputId": "6e415d29-d1fb-46aa-e5fa-09fed1b113e2"
      },
      "source": [
        "#Cleaninng Text\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "corpus = []\n",
        "for i in range(0, 22643):\n",
        "  review = re.sub('[^a-zA-Z]', ' ', df1['Review Text'][i]) #Every symbol,quotes will replaced by space,(^a-zA-Z)-We will not replace letter with space.\n",
        "  review = review.lower()                                   # convert all cases to lower cases \n",
        "  review = review.split()                                    # split to array(default delimiter is \" \") \n",
        "  ps = PorterStemmer()\n",
        "  all_stopwords = stopwords.words('english')\n",
        "  all_stopwords.remove('not')\n",
        "  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqG0vFbyGgJq",
        "outputId": "8a7ad93e-7e8f-418e-89f9-17fdf7b199d6"
      },
      "source": [
        "print(corpus)"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teNTYJasMpBd",
        "outputId": "812d4191-794f-4d13-cbbc-745e14ca7ad8"
      },
      "source": [
        "#finding words in X(review Columns)\n",
        "\n",
        "len(X[0])  #We got 9265 words taken from all the reviews with the help of tokenization, We will take 9000 words for our bag of words model."
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYVjKLyK_6j7"
      },
      "source": [
        "#Creating Bag of Models\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features=1000)  #Max feature is nothing but number of imp words are categorized by model on whoch our model is being trained.Our model categorized 9000 words while we check max feature on 9000 workds we are getting poor accurcay of 40%,while we checked model on 1000 feature we get 73% accuracy.If we further reduce the max feature to 100 words we getting accuracy of 76%\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "y = df1.iloc[:, -1].values"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKaZnlnsAb96"
      },
      "source": [
        "#Splitting model in train and test set\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jVhE8ODAzNp",
        "outputId": "5e245ec4-2aa8-4d4f-b473-9ad13454df93"
      },
      "source": [
        "#Train Naives bayes model on Training Set\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7DyjVUpBnhs",
        "outputId": "526cd12e-0985-4b8c-f522-b000228fac16"
      },
      "source": [
        "#Train set result,73 %accuracy on max feature of 1000,feel free to change max feature in naives bayes to check accuracy on another max feature\n",
        "\n",
        "\n",
        "y_pred = classifier.predict(X_train)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_train.reshape(len(y_train),1)),1))\n",
        "\n",
        "#Confusion matrix for Train Set\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " ...\n",
            " [0 1]\n",
            " [1 1]\n",
            " [0 0]]\n",
            "[[2858  386]\n",
            " [5013 9857]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7019432483162195"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b1QHnqiA72c",
        "outputId": "2709ba97-185a-40ae-a491-3ad361ee1245"
      },
      "source": [
        "#Test set result,73 %accuracy on max feature of 1000,feel free to change max feature in naives bayes to check accuracy on another max feature\n",
        "\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1]\n",
            " [0 1]\n",
            " [1 1]\n",
            " ...\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 1]]\n",
            "[[ 697  160]\n",
            " [1248 2424]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6891145948332965"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMXug3arAn6k"
      },
      "source": [
        ""
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0UFiTlCLTo7",
        "outputId": "dee6aac3-e3b7-4945-a5d0-5f226cdec081"
      },
      "source": [
        "#This model/code is imported from this data set(https://www.geeksforgeeks.org/python-nlp-analysis-of-restaurant-reviews/)\n",
        "#We are able to make 73% of correct prediction on our data set with 22k observations on which our model is trained\n",
        "\n",
        "#Fitting a Predictive Model (here random forest)\n",
        "\n",
        "#Since Random fored is ensemble model (made of many trees) from sklearn.ensemble, import RandomForestClassifier class\n",
        "#With 501 tree or “n_estimators” and criterion as ‘entropy’\n",
        "#Fit the model via .fit() method with attributes X_train and y_train\n",
        "# Fitting Random Forest Classification \n",
        "# to the Training set \n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "  \n",
        "# n_estimators can be said as number of \n",
        "# trees, experiment with n_estimators \n",
        "# to get better results  \n",
        "model = RandomForestClassifier(n_estimators = 500, \n",
        "                            criterion = 'entropy') \n",
        "                              \n",
        "y_pred = classifier.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1]\n",
            " [0 1]\n",
            " [1 1]\n",
            " ...\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 1]]\n",
            "[[ 697  160]\n",
            " [1248 2424]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6891145948332965"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MMrQMpaNMsQ"
      },
      "source": [
        ""
      ],
      "execution_count": 241,
      "outputs": []
    }
  ]
}